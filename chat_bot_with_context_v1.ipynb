{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BerryGIT-ME/NLP/blob/feature%2Fdev-chatbots/chat_bot_with_context_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# We creat a basic context aware chatbot with this notebook.\n",
        "\n",
        "We make use of langchain and llama-index embdeddings\n",
        "\n",
        "Best performance is achieved with a GPU.\n",
        "\n",
        "We make use of openAI embedding models to create the embeddings which are used to provide context to the language model.\n",
        "\n",
        "An open sourced llm model is used - this way the only cost to run the notebook is the cost associated with creating the embeddings"
      ],
      "metadata": {
        "id": "1e3qNLbSk0bQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if a GPU is available\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QDYcisZkTc8",
        "outputId": "b67a7b12-d585-4d7e-928a-56845667101b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: nvidia-smi: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFDDKkJfkQjy",
        "outputId": "3d5925e1-00be-40e2-9d64-730bf9a69aca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m71.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m515.4/515.4 kB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m86.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m83.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m84.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m94.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.8/163.8 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m84.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for sentence_transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# Install dependencies\n",
        "! pip install -q langchain transformers sentence_transformers llama-index"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
        "from langchain.llms.base import LLM\n",
        "from transformers import pipeline\n",
        "from llama_index import (\n",
        "    SimpleDirectoryReader,\n",
        "    LangchainEmbedding,\n",
        "    GPTSimpleVectorIndex,\n",
        "    PromptHelper,\n",
        "    LLMPredictor,\n",
        "    ServiceContext,\n",
        "    StorageContext,\n",
        "    readers,\n",
        "    load_index_from_storage,\n",
        "    Document\n",
        "    )\n",
        "import torch\n",
        "import openai"
      ],
      "metadata": {
        "id": "aGCX8IBekbNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key = 'Your openai api key'"
      ],
      "metadata": {
        "id": "QJcrPrQ3RK5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# langchain wrapper for a custom llm\n",
        "class customLLM(LLM):\n",
        "    model_name = \"google/flan-t5-large\"\n",
        "    pipeline = pipeline(\"text2text-generation\", model=model_name, device=0, model_kwargs={\"torch_dtype\":torch.bfloat16})\n",
        "\n",
        "    def _call(self, prompt, stop=None):\n",
        "        return self.pipeline(prompt, max_length=9999)[0][\"generated_text\"]\n",
        "\n",
        "    @property\n",
        "    def _identifying_params(self):\n",
        "        return {\"name_of_model\": self.model_name}\n",
        "\n",
        "    @property\n",
        "    def _llm_type(self):\n",
        "        return \"custom\"\n",
        "\n",
        "\n",
        "llm_predictor = LLMPredictor(llm=customLLM())\n",
        "\n"
      ],
      "metadata": {
        "id": "nVcWX65LkfG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hfemb = HuggingFaceEmbeddings()\n",
        "embed_model = LangchainEmbedding(hfemb)"
      ],
      "metadata": {
        "id": "Noq5r9_jkiVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text1 = \"\"\"\n",
        "Enabling Mobile Payment and Digital Finance in Africa\n",
        "QOS APIs allow companies of all sizes — from startups to large enterprises — to accept payments, make transfers, receive payouts, and manage their businesses online\n",
        "Do you have a sandbox where I can test your API?\n",
        "\n",
        "Yes, we have a sandbox for you to test the API. Check the developer page of our website for more information on the sandbox. Create an account and to start accepting payment.\n",
        "\n",
        "How do I receive the money paid by my customers?\n",
        "\n",
        "You will be settled within 24 hours after a successful payment and you can withdraw your money to you registered account at any time after settlement.\n",
        "\n",
        "Do I need a Merchant Mobile Money Account?\n",
        "\n",
        "For mobile money payout, it is advisable to have a merchant account for payout because you can link the merchant account to your bank account. However, payout can be done to any mobile money account number Visit the operator’s mobile money office to register for a merchant account if you don’t already have one.\n",
        "\n",
        "How long does it take for me to get my money (settlement)?\n",
        "\n",
        "Settlement to your QOS account is done within 48 hours after a successful payment.\n",
        "\n",
        "How much do you charge to integrate to the API?\n",
        "\n",
        "Integration with our API is free. You can create an account here.\n",
        "\n",
        "How much do you charge to develop a USSD menu?\n",
        "\n",
        "The price for developing your USSD menu depends on the complexity of your customer journey. We will be glad to discuss with you to find a suitable solution for your use case.\n",
        "\n",
        "How much do you charge to onboard on Mobile Money USSD?\n",
        "\n",
        "It is free to onboard on QOS position on the mobile money USSD menu.\n",
        "\n",
        "Do you charge fee/commission on collection?\n",
        "\n",
        "There is 1.7% commission on every successful payment transaction you receive.\n",
        "\n",
        "Do you charge for transfers (disbursement)?\n",
        "\n",
        "There is 1% on every successful transfer to other mobile money accounts.\n",
        "\n",
        "Do you charge for payout to my account (settlement)?\n",
        "\n",
        "Payout into your account is free.\n",
        "\n",
        "Does integrating your API give access to other countries?\n",
        "\n",
        "At this moment, our API gives you access to Benin, Togo and Cote D’Ivoire. As we add more countries, we shall notify you accordingly\n",
        "\n",
        "Do you offer transactions volume discounts ?\n",
        "\n",
        "Yes, high volume customers can benefit from a reduced commission on transaction volumes. Please contact sales for more information.\n",
        "\n",
        "Are you able to offer flat rate per transactions?\n",
        "\n",
        "Yeah, we offer flat rate per transaction to businesses such Microfinance. In this scenario, we charge a flat fee per successful transaction. Please contact sales to discuss further.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "-R7tALDKn1X2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To load from a stored text file uncomment the next line of code\n",
        "#documents = SimpleDirectoryReader('data').load_data()\n",
        "\n",
        "cdocuments = [Document(t) for t in [text1]]"
      ],
      "metadata": {
        "id": "DFM8PBkZpsaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "logging.getLogger().setLevel(logging.CRITICAL)"
      ],
      "metadata": {
        "id": "-0-zPX2ZMfzE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create new index from documents\n",
        "\n"
      ],
      "metadata": {
        "id": "I1uCcl39MRlK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "service_context = ServiceContext.from_defaults(llm_predictor=llm_predictor, embed_model=embed_model)\n",
        "index = GPTSimpleVectorIndex.from_documents(documents, service_context=service_context)"
      ],
      "metadata": {
        "id": "B2oE7bPfpyif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path = 'index_store'\n",
        "index.storage_context.persist(persist_dir=folder_path)"
      ],
      "metadata": {
        "id": "50Z9TffJSTto"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_engine = index.as_query_engine()\n",
        "response = query_engine.query(\"what are the articles about?\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "B_LucNzXavpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"what offers can I get from qos?\")\n",
        "print(response)\n"
      ],
      "metadata": {
        "id": "U6ei1YUCp2IX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"How are customers charged for the use of qos apis\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "TY7ib2sngbFK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"what about commissions?\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "4F6uX7FvgmI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load previously saved index from hard drive"
      ],
      "metadata": {
        "id": "RMU6lgGrMvv8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path = 'index_store'\n",
        "storage_context = StorageContext.from_defaults(persist_dir=folder_path)\n",
        "index2 = load_index_from_storage(storage_context, service_context=service_context)"
      ],
      "metadata": {
        "id": "5ULT6VJZhriD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_engine2 = index2.as_query_engine()\n",
        "response = query_engine2.query(\"what are the articles about?\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhebpp8-f77d",
        "outputId": "bb30cf89-92a2-45cd-fd92-e44772a1ff63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "QOS APIs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wwFjGtsrhZKf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}